{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aY3CajZT2QRX"
   },
   "source": [
    "# PRÁTICA GUIADA: Introdução a Machine Learning 1\n",
    "\n",
    "#### Agora, vamos analisar vários exemplos simples de aplicação de métodos de aprendizagem supervisionada e não supervisionada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FvZMcTJ02QRZ"
   },
   "source": [
    "### Exemplo de aprendizagem supervisionada: Regressão linear simples\n",
    "\n",
    "#### Como exemplo desse processo, vamos considerar uma regressão linear simples, ou seja, o caso comum de ajustar uma linha a dados com a forma $(x, y)$.\n",
    "\n",
    "#### Vamos importar a classe de pacotes [`matplotlib.pyplot`](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.html) para plotar os valores que vamos criar com o auxílio da função [`np.random.RandomState()`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.RandomState.html), gerando um conjunto de dados para nosso exemplo de regressão:\n",
    "\n",
    "#### [`.scatter()`](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.scatter.html#matplotlib.pyplot.scatter) para investigar a dispersão entre os pontos gerados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "b_b0W2g12QRZ"
   },
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "x = 10 * rng.rand(50)\n",
    "y = 2 * x - 1 + rng.randn(50)\n",
    "\n",
    "# Traçamos\n",
    "plt.scatter(x, y);\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Miv8qlch2QRf"
   },
   "source": [
    "#### Depois de gerar os dados, podemos usar a receita que estudamos antes. Vamos ver os passos do processo: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ecpXCOQr2QRg"
   },
   "source": [
    "### 1. Selecionar uma “classe de modelo”\n",
    "\n",
    "- Em Scikit-Learn, cada [classe de modelo](https://scikit-learn.org/stable/tutorial/basic/tutorial.html) é representada com uma classe de Python. \n",
    "\n",
    "- Então, por exemplo, se queremos calcular um modelo de [regressão linear simples](https://en.wikipedia.org/wiki/Regression_analysis), podemos importar a classe de regressão linear desta forma:\n",
    "\n",
    "- Vamos importar a classe de funções [`sklearn.linear_model.LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Iflkv6iz2QRg"
   },
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "from sklearn.linear_model import LinearRegression\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1kcJ8AxX2QRl"
   },
   "source": [
    "#### Lembre que também existem outros modelos de regressão linear mais gerais. Você pode ler mais sobre eles na documentação [`sklearn.linear_model`](http://Scikit-Learn.org/stable/modules/linear_model.html). Aqui escolheremos o modelo de [`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DFDCDxTi2QRm"
   },
   "source": [
    "### 2. Escolher os hiperparâmetros do modelo\n",
    "\n",
    "#### É importante destacar que *uma classe de modelo não é a mesma coisa que uma instância de modelo*.\n",
    "\n",
    "#### Depois de definir a classe de modelo, ainda é preciso tomar algumas decisões. Dependendo da classe de modelo escolhida para trabalhar, poderíamos ter que responder a uma ou mais perguntas, por exemplo:\n",
    "\n",
    "- Queremos ajustar também uma interceptação (intercept = True)?\n",
    "- Queremos que o modelo esteja normalizado?\n",
    "- Queremos adicionar features calculadas a partir do input para aumentar a flexibilidade do modelo?\n",
    "- Que grau de \"regularização\" queremos usar no modelo?\n",
    "\n",
    "#### Esses são exemplos das decisões importantes que devem ser tomadas **depois de selecionar a classe de modelo a usar**.\n",
    "\n",
    "#### Freqüêntemente, essas escolhas são representadas como *hiperparâmetros*, ou parâmetros que devem ser definidos antes que o modelo seja ajustado aos dados. \n",
    "\n",
    "#### Em Scikit-Learn, os hiperparâmetros são escolhidos como argumentos na instanciação do modelo. Nas próximas aulas, vamos explorar como justificar quantitativamente a escolha de hiperparâmetros.  \n",
    "\n",
    "#### Para o nosso exemplo de regressão linear, vamos criar um objeto que receberá o modelo que pretendemos criar com a função [``LinearRegression()``](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). Observe a parametrização `fit_intercept = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WQeCLbrL2QRm"
   },
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "model = LinearRegression(fit_intercept = True)\n",
    "print(model)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NsCpHWqS2QRr"
   },
   "source": [
    "#### **Atenção**: quando o modelo é instanciado, a única ação que acontece é o armazenamento dos valores de hiperparâmetros.\n",
    "\n",
    "#### Especificamente, ainda não aplicamos o modelo a nenhum dado: a API de Scikit-Learn faz uma distinção muito clara entre a *escolha do modelo com hiperparâmetros* e a *aplicação do modelo aos dados*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k9wKJHWW2QRs"
   },
   "source": [
    "### 3. Preparar os dados em uma matriz de `features` e um vetor `target`.\n",
    "\n",
    "#### Já falamos da representação de dados de Scikit-Learn, que exige uma matriz de `features` de duas dimensões e um vetor `target` de uma dimensão.\n",
    "\n",
    "#### Aqui, a variável `target` `y` já está no formato correto (um array de comprimento `n_samples`), mas precisamos processar os dados em `x` para transformá-los em uma matriz de tamanho `[n_samples, n_features]`.\n",
    "\n",
    "#### Vamos criar um objeto `x` e checar suas dimensões com o atributo [`.ndim` ](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.ndim.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "x\n",
    "x.ndim\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nesse caso, isso se reduz a uma simples mudança de forma ([reshaping](https://towardsdatascience.com/reshaping-numpy-arrays-in-python-a-step-by-step-pictorial-tutorial-aed5f471cf0b)) do array de uma dimensão. Para isso podemos usar a função [`np.newaxis()`](https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis) reindexar o objeto e atribuí-lo a `X`. \n",
    "\n",
    "#### Uma outra forma de alterar o formato do seu arranjo pode ser feito com a aplicação do método [`.reshape(-1,1)()`](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uI_0VWMP2QRu"
   },
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "X = x[:, np.newaxis]\n",
    "X.shape\n",
    "\n",
    "# Outra forma de fazer isso\n",
    "X = x.reshape(-1,1)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando novamente o número de dimensões, agora do objeto `X`, temos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "X\n",
    "X.ndim\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKxsfV_Y2QRx"
   },
   "source": [
    "### 4. Ajustar o modelo aos dados\n",
    "\n",
    "#### Agora, é hora de aplicar o modelo aos dados. Vamos fazer o ajuste dos dados ao modelo com o método [`.fit()`](https://scikit-learn.org/stable/tutorial/basic/tutorial.html) da instância de modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_6DVnzS32QRy"
   },
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "model.fit(X, y)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "khLkXfRt2QR2"
   },
   "source": [
    "#### O método [`.fit()`](https://scikit-learn.org/stable/tutorial/basic/tutorial.html) faz uma sequência de cálculos internos que dependem do modelo, e os resultados dessas operações são armazenados em atributos específicos da classe de modelo que o usuário poderá explorar.\n",
    "\n",
    "#### Em Scikit-learn, por convenção, todos os atributos que representam os parâmetros dos modelos que foram aprendidos durante o processo de treinamento com `fit()` têm `sublinhados` nos nomes; por exemplo, neste modelo linear, podemos observar os parâmetros [`coef_`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) e [`intercept_`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dAKoaQvI2QR2"
   },
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "a = model.intercept_\n",
    "b = model.coef_\n",
    "print(a)\n",
    "print(b)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aqui os atributos `coef_` e `intercept_` representam os coeficientes linear (a) angular (b), respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p1tr4WDb2QR_"
   },
   "source": [
    "#### Esses dois parâmetros representam a pendente e a interceptação do ajuste linear simples aos dados. Fazendo uma comparação com a definição do conjunto de dados sintético criado no início do exemplo, podemos ver que eles estão muito próximos da pendente `2` e da interceptação `-1`, definidas na fórmula para gerar os dados.\n",
    "\n",
    "#### Uma pergunta que surge com frequência tem a ver com a incerteza (uncertainty) nesses parâmetros internos do modelo. \n",
    "\n",
    "#### Em geral, Scikit-Learn não oferece ferramentas para tirar conclusões sobre o estado interno dos modelos: interpretar os parâmetros de um modelo tem muito mais a ver com *modelagem estatística* que com *machine learning*.\n",
    "\n",
    "#### Machine learning, por sua vez, enfoca a qualidade com a qual o modelo *faz previsões*.\n",
    "\n",
    "#### Se quiser investigar o significado dos parâmetros de ajuste dentro do modelo, existem outras ferramentas, incluindo o pacote de python [Statsmodels](http://statsmodels.sourceforge.net/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_MTUUUX2QSA"
   },
   "source": [
    "### 5. Prever tags para dados desconhecidos:\n",
    "\n",
    "#### Depois que o modelo é treinado, a principal tarefa na aprendizagem supervisionada é fazer uma avaliação com base no que o modelo diz sobre os novos dados que não fizeram parte do **conjunto de treinamento**. \n",
    "\n",
    "#### A função [`.linspace()`](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace) retorna um intervalo específico com valores igualmente espaçados. Assim como antes, precisamos manipular os valores `x` em uma matriz de features de tamanho `[n_samples, m_features]`. Só depois desse passo será possível utilizá-la como argumento para a previsão. \n",
    "\n",
    "#### Vamos então instanciar um objeto que irá receber o resultado de [`.linspace()`](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yEoiN7IH2QSB"
   },
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "xfit = np.linspace(-1, 11)\n",
    "xfit\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplique novamente a função [`np.newaxis()`](https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis) para reindexar o objeto criado na célula anterior.\n",
    "\n",
    "#### Usando o método [`.predict()`](https://scipy-lectures.org/packages/scikit-learn/index.html#:~:text=predict()%20%3A%20given%20a%20trained,each%20object%20in%20the%20array.) vamos analisar as previsões dos rótulos de saída, gerados pelo meodelo . No contexto deste exemplo, o “novo conjunto de dados” será um vetor de valores `x` , e observaremos os valores `y` previstos pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RQJD-1jo2QSF"
   },
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "Xfit = xfit[:, np.newaxis]\n",
    "Xfit\n",
    "yfit = model.predict(Xfit)\n",
    "yfit\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWKSkW7d2QSK"
   },
   "source": [
    "#### Por último, para visualizar os resultados, vamos traçar primeiro os dados originais e, em seguida, o ajuste do modelo linear, com as funções [`plt.scatter`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html) e [`plt.plot`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DCIqoLg32QSK"
   },
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xfit, yfit);\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d3hPrUOi2QSQ"
   },
   "source": [
    "#### Normalmente, a eficácia do modelo é avaliada por meio da comparação dos resultados com algum baseline conhecido, como veremos no próximo exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0mw3E22L2QSR"
   },
   "source": [
    "### Exemplo de aprendizagem supervisionada: Classificação com o conjunto de dados Iris.\n",
    "\n",
    "#### Vamos ver mais um exemplo desse processo, usando o conjunto de dados `Iris` que mencionamos antes. A pergunta será esta: usando um modelo treinado em uma parte do conjunto de dados Iris, com que eficácia será possível prever as `tags`  restantes?\n",
    "\n",
    "#### Vamos primeiramente importar a biblioteca [`seaborn`](https://seaborn.pydata.org/) e carregar o dataset `iris` com a função [`sns.load_dataset()`](https://seaborn.pydata.org/generated/seaborn.load_dataset.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OBiFLmpK2QSS"
   },
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "import seaborn as sns\n",
    "iris = sns.load_dataset('iris')\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primeiramente examine as primeiras linhas do código, depois crie um novo dataframe `X_iris` sem a coluna `'species'`, assim poderemos treinar nosso modelos. Cheque o formato e novamente as primeiras linhas do novo dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nLqPKOaX2QSV"
   },
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "iris.head()\n",
    "iris.shape\n",
    "#X_iris = iris.drop('species', axis = 1)\n",
    "#X_iris.shape\n",
    "#X_iris.head()\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crie também um objeto `y_iris`  que receba os rótulos do dataframe iris, a coluna `'species'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3GZ3GXQO2QSY"
   },
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "y_iris = iris['species']\n",
    "y_iris.shape\n",
    "y_iris.head()\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0RgMjfY_2QSb"
   },
   "source": [
    "#### Para esta tarefa, vamos usar um modelo generativo bastante simples, conhecido como [Naive Bayes Gaussiano](https://machinelearningmastery.com/naive-bayes-for-machine-learning/#:~:text=This%20extension%20of%20naive%20Bayes,deviation%20from%20your%20training%20data), que presume que cada classe é construída a partir de uma distribuição Gaussiana. Vamos ver mais detalhes sobre ele mais adiante no curso.\n",
    "\n",
    "- Como é muito rápido e não tem hiperparâmetros para escolher, Naive Bayes Gaussiano costuma ser um bom modelo para usar como classificação baseline antes de explorar se é possível conseguir melhorias usando modelos mais sofisticados.\n",
    "\n",
    "- Queremos avaliar o modelo em dados que não tenham sido usados no treinamento, por isso vamos dividir os dados em um *conjunto de treinamento* e um *conjunto de teste*.\n",
    "\n",
    "- Poderíamos fazer isso manualmente, mas é mais prático usar a função [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "#### Para isso importe a classe de funções [`sklearn.model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) e aplique a função [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#) às amostras `X_iris` e `y_iris`, observando o parâmetro `random_state = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "78j80s0Z2QSc"
   },
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_iris, y_iris, random_state = 1 )\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3c3F3S8w2QSh"
   },
   "source": [
    "\n",
    "#### Com os dados preparados, podemos seguir a receita para prever as tags:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "O-M6EXi32QSi"
   },
   "source": [
    "- 1. escolher a classe de modelo. Nesse caso o modelo Gaussiano de Naive Bayes [`from sklearn.naive_bayes.GaussianNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2. instanciar o modelo. Usar a função [`GaussianNB()`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) para instanciar um modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "model = GaussianNB()\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3. ajustar o modelo aos dados. Aqui é possível fazer uso do método [`.fit()`](https://scikit-learn.org/stable/tutorial/basic/tutorial.html), para ajustar os pontos de de treino para `X`e `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "model.fit(Xtrain, ytrain)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4. prever a partir de novos dados. O método `.predict()` realiza a predição a partir dos dados de teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "y_model = model.predict(Xtest)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a1EkA6kP2QSl"
   },
   "source": [
    "#### A classe [`sklearn.metrics.accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) fornece ferramentas para checar a acurácia com que o modelo realizou suas previsões, ela deve ser importada.\n",
    "\n",
    "#### Usamos a função [`.accuracy_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) para estudar a proporção de tags previstas que coincidem com o valor real correspondente a essa observação. Aqui testaremos os valores `y` de teste e `y` de modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yn-EOlo32QSn"
   },
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest, y_model)\n",
    "\n",
    "#### Com precisão superior a 97%, podemos ver que até mesmo esse simples algoritmo de classificação é efetivo para esse conjunto de dados específico.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a2QiIqT02QSr"
   },
   "source": [
    "### Exemplo de aprendizagem não supervisionada: Dimensionalidade de Iris.\n",
    "\n",
    "#### Como exemplo de problema de aprendizagem não supervisionado, vamos ver como reduzir a dimensionalidade dos dados de Iris para facilitar a visualização. \n",
    "\n",
    "#### Lembre que o conjunto de dados Iris tem quatro dimensões: há quatro features medidas para cada observação (sample).\n",
    "\n",
    "#### A tarefa de redução da dimensionalidade é investigar se existe uma representação apropriada de baixa dimensionalidade que mantenha as características essenciais do conjunto de dados original. \n",
    "\n",
    "#### Freqüêntemente, a redução da dimensionalidade é usada como ajuda para visualizar os dados: afinal, é muito mais fácil traçar os dados em duas dimensões que em quatro ou mais. \n",
    "\n",
    "#### Neste exemplo, vamos usar o modelo [Principal Component Analysis](https://towardsdatascience.com/principal-component-analysis-pca-from-scratch-in-python-7f3e2a540c51) (PCA), que é uma técnica rápida de redução linear da dimensionalidade. Vamos submeter os dados à classe de funções [`sklearn.decomposition.PCA`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) e pedir para o modelo retornar dois componentes, ou seja, uma representação bidimensional dos dados. \n",
    "\n",
    "#### Seguindo a sequência de passos apresentada anteriormente, temos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1. Selecionar a classe de modelo. Importe a classe de funções [`sklearn.decomposition.PCA`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "from sklearn.decomposition import PCA\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2. Instanciar o modelo com hiperparâmetros. Aplicamos a função [`PCA()`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html), observando o parâmetro `n_components = 2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "model = PCA(n_components = 2)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3. Ajustar aos dados. Observar que não especificamos “y”. Aplicamos o método [`.fit()`](https://scikit-learn.org/stable/tutorial/basic/tutorial.html) ao objeto que instancia o modelo ao conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "model.fit(X_iris)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4. Transformar os dados em duas dimensões com a função [`.transform()`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA.transform), podemos criar um objeto que receba a transformação dos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "X_2D = model.transform(X_iris)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "262GtvTx2QSv"
   },
   "source": [
    "#### Agora, vamos traçar os resultados. Uma forma rápida de fazer isso é inserir os resultados no `DataFrame` original de Iris e usar o método [`.lmplot()`](https://seaborn.pydata.org/generated/seaborn.lmplot.html) de Seaborn para mostrar os resultados.\n",
    "\n",
    "Podemos alimentar o dataframe `iris` com as colunas `PCA1` e `PCA2` geradas com o modelo e então realizar o plot dessas quantidades, obsservando os parâmetros `hue = 'species' e fit_reg = False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QyEWlsMj2QSv"
   },
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "iris['PCA1'] = X_2D[:, 0]\n",
    "iris['PCA2'] = X_2D[:, 1]\n",
    "sns.lmplot(\"PCA1\", \n",
    "           \"PCA2\", \n",
    "           hue = 'species', \n",
    "           data = iris, \n",
    "           fit_reg = False\n",
    "          );\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcZbXtJW2QS0"
   },
   "source": [
    "#### Vemos que, na representação em duas dimensões, as espécies estão relativamente bem separadas, ainda que o algoritmo PCA não tivesse conhecimento das tags das espécies de flores! \n",
    "\n",
    "#### Isso indica que uma classificação relativamente simples deveria funcionar com esse conjunto de dados, como vimos antes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XXl2mRsh2QS1"
   },
   "source": [
    "### Aprendizagem não supervisionada: Clustering com Iris\n",
    "\n",
    "#### Vamos aplicar um algoritmo de clustering ao conjunto de dados Iris.\n",
    "\n",
    "#### Um algoritmo de clustering tenta encontrar grupos diferentes sem fazer referência a tags nos dados. \n",
    "\n",
    "#### Vamos usar um método avançado de clustering chamado [Gaussian Mixture Model](https://scikit-learn.org/stable/modules/mixture.html#:~:text=sklearn.,of%20components%20are%20also%20provided.) (GMM). O GMM tenta modelar os dados como uma coleção de blobs Gaussianos. \n",
    "\n",
    "#### Podemos ajustar o [GMM](https://towardsdatascience.com/gaussian-mixture-models-explained-6986aaf5a95) da seguinte forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1. Escolhemos a classe de modelo. Importe a classe de funções [`sklearn.mixture.GaussianMixture`](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "from sklearn.mixture import GaussianMixture\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2. Instanciamos o modelo com hiperparâmetros usando a função [`GaussianMixture()`](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html), observando os parâmetros `n_components = 3` e `covariance_type = 'full'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "model = GaussianMixture(n_components = 3, covariance_type = 'full')\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3. Ajustamos aos dados. Para isso aplicamos novamente a função [`.fit()`](https://scikit-learn.org/stable/tutorial/basic/tutorial.html) ao objeto que instancia o modelo ao conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "model.fit(X_iris)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4. Definimos as tags dos clusters de saída. Aqui podemos usar a função [`.predict()`](https://scipy-lectures.org/packages/scikit-learn/index.html#:~:text=predict()%20%3A%20given%20a%20trained,each%20object%20in%20the%20array.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "y_gmm = model.predict(X_iris)\n",
    "y_gmm\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NIK-WHh02QS4"
   },
   "source": [
    "#### Como antes, vamos adicionar as tags dos clusters ao `DataFrame` Iris e usar `Seaborn` para traçar os resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "iris['cluster'] = y_gmm\n",
    "iris.head()\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agora, vamos traçar os resultados. Uma forma rápida de fazer isso é inserir os resultados no `DataFrame` original de Iris e usar o método [`.lmplot()`](https://seaborn.pydata.org/generated/seaborn.lmplot.html) de Seaborn para mostrar os resultados. Vamos novamente plotar os resultados da aproximação [Principal Component Analysis](https://medium.com/@aptrishu/understanding-principle-component-analysis-e32be0253ef0), mas agora adotando o paâmetro `col = 'cluster'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JDLDYV3p2QS5"
   },
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "sns.lmplot(\"PCA1\", \n",
    "           \"PCA2\", \n",
    "           data = iris, \n",
    "           hue = 'species', \n",
    "           col = 'cluster', \n",
    "           fit_reg = False\n",
    "          );\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QWLVh-122QS-"
   },
   "source": [
    "#### Depois de separar os dados por número de cluster, vemos exatamente o grau de eficiência com que o algoritmo GMM recuperou a tag subjacente: a espécie *setosa* é separada perfeitamente dentro do cluster 0, embora apareça uma pequena parte misturada entre *versicolor* e *virginica*. \n",
    "\n",
    "#### Isso significa que mesmo sem um especialista que nos diga as tags de cada flor, as medidas dessas observações são suficientemente diferentes para que seja possível identificar *automaticamente* a presença desses diferentes grupos de espécies com um simples algoritmo de clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xpqbZJmg2QTA"
   },
   "source": [
    "## Resumindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XA-zhrPf2QTC"
   },
   "source": [
    "#### Nesta seção, abordamos as características essenciais da representação de dados em Scikit-Learn e a API de estimadores. \n",
    "\n",
    "#### Sem importar o tipo de estimador, o mesmo padrão de importar/instanciar/ajustar/prever se mantém em todos os casos. \n",
    "\n",
    "#### Com essas novas informações sobre a API de estimadores, você pode explorar a documentação de Scikit-Learn e começar a testar vários modelos sobre os dados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rEOUtQpm2QTD"
   },
   "source": [
    "####  <span style = \"color:blue\">Código Original.</span>\n",
    "<!---\n",
    "[``]()\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "PRACTICA_GUIADA_Intro_ML_Sklearn_pt_br.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
